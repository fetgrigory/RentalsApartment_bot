'''
This module make
Author: Fetkulin Grigory, Fetkulin.G.R@yandex.ru
Starting 17/05/2025
Ending //

'''
# Installing the necessary libraries
import os
from transformers import pipeline
from ollama import Client, ChatResponse

# System prompt for GPT to define its behavior
system_prompt = """
Ð¢Ñ‹ â€” Ð²Ð¸Ñ€Ñ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº ÑÐµÑ€Ð²Ð¸ÑÐ° Ð°Ñ€ÐµÐ½Ð´Ñ‹ ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð²ÐµÐ¶Ð»Ð¸Ð²Ð¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ.

**ÐŸÑ€Ð°Ð²Ð¸Ð»Ð°:**
1. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ñ Ð°Ñ€ÐµÐ½Ð´Ð¾Ð¹ Ð¶Ð¸Ð»ÑŒÑ
2. ÐÐµ Ð´Ð°Ð²Ð°Ð¹ ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ð¹ (Ð¿ÐµÑ€ÐµÐ½Ð°Ð¿Ñ€Ð°Ð²Ð»ÑÐ¹ Ðº Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¼ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð°Ð¼)
3. ÐÐ° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¾ Ñ†ÐµÐ½Ð°Ñ…/Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸ Ð¿Ñ€ÐµÐ´Ð»Ð°Ð³Ð°Ð¹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€Ð°Ð·Ð´ÐµÐ» ðŸ›ÐšÐ°Ñ‚Ð°Ð»Ð¾Ð³
4. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐ¹ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ð¾Ð½
5. Ð•ÑÐ»Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð½ÐµÑÑÐµÐ½ â€” ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸ Ð´ÐµÑ‚Ð°Ð»Ð¸
6. ÐÐ° Ð¾Ñ‚ÐºÐ»Ð¾Ð½Ð¸Ð²ÑˆÐ¸ÐµÑÑ Ñ‚ÐµÐ¼Ñ‹ Ð²ÐµÐ¶Ð»Ð¸Ð²Ð¾ ÑÐ¾Ð¾Ð±Ñ‰Ð°Ð¹ Ð¾ Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ
"""


# Get response from GPT model
def ask_gpt(messages: list) -> str:
    """AI is creating summary for ask_gpt

    Args:
        messages (list): [description]

    Returns:
        str: [description]
    """
    try:

        api_url = os.getenv("OLLAMA_API_URL", "http://localhost:11434")
        client = Client(host=api_url)
        # Add system prompt to the beginning of messages
        messages_with_system = [{"role": "system", "content": system_prompt}] + messages
        response: ChatResponse = client.chat(
            model='yandex/YandexGPT-5-Lite-8B-instruct-GGUF:latest',
            messages=messages_with_system,
        )
        return response.message.content

    except Exception as e:
        print(f"Error getting GPT response: {e}")
        return "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð² Ð´Ð°Ð½Ð½Ñ‹Ð¹ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ Ñ Ð½Ðµ Ð¼Ð¾Ð³Ñƒ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚ÑŒ Ð½Ð° Ð²Ð°Ñˆ Ð²Ð¾Ð¿Ñ€Ð¾Ñ. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ."


# Loads and returns the sentiment analysis model
def load_sentiment_model():
    """AI is creating summary for load_sentiment_model

    Returns:
        [type]: [description]
    """
    return pipeline(
        task='sentiment-analysis',
        model='blanchefort/rubert-base-cased-sentiment'
    )


# Loading the model when importing the module
sentiment_analyzer = load_sentiment_model()


# Analyzes the review text and returns the result
def analyze_review(text: str) -> dict:

    """AI is creating summary for

    Returns:
        [type]: [description]
    """
    result = sentiment_analyzer(text)[0]
    return {
        "label": result["label"],
        "score": result["score"]
    }
