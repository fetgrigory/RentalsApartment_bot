'''
This module make
Author: Fetkulin Grigory, Fetkulin.G.R@yandex.ru
Starting 17/05/2025
Ending //

'''
# Installing the necessary libraries
import os
from transformers import pipeline
from ollama import Client, ChatResponse

# System prompt for GPT to define its behavior
system_prompt = """
Ð¢Ð¸Ð¿ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°: ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ

Ð¢Ñ‹ â€” Ð²Ð¸Ñ€Ñ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº ÑÐµÑ€Ð²Ð¸ÑÐ° Ð°Ñ€ÐµÐ½Ð´Ñ‹ ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€.

Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° â€” ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚ÑŒ Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¹ Ð¸Ð· ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹ Ð½Ð¸Ð¶Ðµ.
ÐžÑ‚Ð²ÐµÑ‚ Ð²ÑÐµÐ³Ð´Ð° Ð²Ñ‹Ð±Ð¸Ñ€Ð°Ð¹ ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ð¼ Ð¸ Ð½Ðµ Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÑÐ¹ÑÑ Ð¾Ñ‚ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¾Ð².

ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²:

1. âŒ ÐÐµ Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ (Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð½Ðµ ÑÐ²ÑÐ·Ð°Ð½ Ñ Ð°Ñ€ÐµÐ½Ð´Ð¾Ð¹ Ð¶Ð¸Ð»ÑŒÑ):
   ÐžÑ‚Ð²ÐµÑ‚: "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ñ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸ Ð¿Ð¾ Ð°Ñ€ÐµÐ½Ð´Ðµ Ð¶Ð¸Ð»ÑŒÑ."

2. âš–ï¸ Ð®Ñ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ (Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€, Ð·Ð°ÐºÐ¾Ð½, Ð¿Ñ€Ð°Ð²Ð°, Ñ€Ð°ÑÑ‚Ð¾Ñ€Ð¶ÐµÐ½Ð¸Ðµ):
   ÐžÑ‚Ð²ÐµÑ‚: "ÐŸÐ¾ ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÑŽ Ð¾Ð±Ñ€Ð°Ñ‚Ð¸Ñ‚ÑŒÑÑ Ðº ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ñƒ."

3. ðŸ› ÐšÐ°Ñ‚Ð°Ð»Ð¾Ð³ (Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¾ ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€Ð°Ñ…, Ñ†ÐµÐ½Ð°Ñ…, Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð°Ñ…, Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸):
   ÐžÑ‚Ð²ÐµÑ‚: "ðŸ›ÐšÐ°Ñ‚Ð°Ð»Ð¾Ð³: Ð²Ñ‹ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹ ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€ Ð² Ð½Ð°ÑˆÐµÐ¼ ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ðµ."

4. ðŸ¡ Ð£Ñ‚Ð¾Ñ‡Ð½ÑÑŽÑ‰Ð¸Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, â€œÐ¥Ð¾Ñ‡Ñƒ ÑÐ½ÑÑ‚ÑŒ ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€Ñƒâ€):
   ÐžÑ‚Ð²ÐµÑ‚: Ð·Ð°Ð´Ð°Ð¹ 2â€“3 ÑƒÑ‚Ð¾Ñ‡Ð½ÑÑŽÑ‰Ð¸Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°:
     - "ÐšÐ°ÐºÐ¾Ð¹ Ñ‚Ð¸Ð¿ Ð¶Ð¸Ð»ÑŒÑ Ð²Ñ‹ Ð¸Ñ‰ÐµÑ‚Ðµ?"
     - "ÐÐ° ÐºÐ°ÐºÐ¾Ð¹ ÑÑ€Ð¾Ðº Ð¿Ð»Ð°Ð½Ð¸Ñ€ÑƒÐµÑ‚Ðµ Ð°Ñ€ÐµÐ½Ð´Ñƒ?"
     - "Ð’ ÐºÐ°ÐºÐ¾Ð¼ Ñ€Ð°Ð¹Ð¾Ð½Ðµ Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°ÐµÑ‚Ðµ Ð¶Ð¸Ð»ÑŒÑ‘?"

Ð—Ð°Ð¿Ñ€ÐµÑ‰ÐµÐ½Ð¾:
- ÐŸÑ€Ð¸Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ñ‚ÑŒ Ñ†ÐµÐ½Ñ‹, ÑÐ¿Ð¸ÑÐºÐ¸, Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€.
- Ð”Ð°Ð²Ð°Ñ‚ÑŒ ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ¾Ð²ÐµÑ‚Ñ‹.
- Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð¸Ðµ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð², ÐºÑ€Ð¾Ð¼Ðµ Ð¿ÐµÑ€ÐµÑ‡Ð¸ÑÐ»ÐµÐ½Ð½Ñ‹Ñ….

Ð•ÑÐ»Ð¸ Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑˆÑŒ Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ â€” Ð²Ñ‹Ð±ÐµÑ€Ð¸ Ð¿ÑƒÐ½ÐºÑ‚ 1.
"""


# Get response from GPT model
def ask_gpt(messages: list) -> str:
    """AI is creating summary for ask_gpt

    Args:
        messages (list): [description]

    Returns:
        str: [description]
    """
    try:

        api_url = os.getenv("OLLAMA_API_URL")
        client = Client(host=api_url)
        # Add system prompt to the beginning of messages
        messages_with_system = [{"role": "system", "content": system_prompt}] + messages
        response: ChatResponse = client.chat(
            model='infidelis/GigaChat-20B-A3B-instruct:q4_0',
            messages=messages_with_system,
        )
        return response['message']['content']

    except Exception as e:
        print(f"Error getting GPT response: {e}")
        return "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð² Ð´Ð°Ð½Ð½Ñ‹Ð¹ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ Ñ Ð½Ðµ Ð¼Ð¾Ð³Ñƒ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚ÑŒ Ð½Ð° Ð²Ð°Ñˆ Ð²Ð¾Ð¿Ñ€Ð¾Ñ. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ."


# Loads and returns the sentiment analysis model
def load_sentiment_model():
    """AI is creating summary for load_sentiment_model

    Returns:
        [type]: [description]
    """
    return pipeline(
        task='sentiment-analysis',
        model='blanchefort/rubert-base-cased-sentiment'
    )


# Loading the model when importing the module
sentiment_analyzer = load_sentiment_model()


# Analyzes the review text and returns the result
def analyze_review(text: str) -> dict:

    """AI is creating summary for

    Returns:
        [type]: [description]
    """
    result = sentiment_analyzer(text)[0]
    return {
        "label": result["label"],
        "score": result["score"]
    }
